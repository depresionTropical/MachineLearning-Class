{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Componentes Principales\n",
    "\n",
    "## Método de Analisis de Componentes Principales (PCA)\n",
    "\n",
    "Es un método de `Machinie Learning` usado regularmente para reducir la dimensionalidad de grandes `datasets`, tranformando un gran `datasets`en uno más pequeño conservando la mayor parte de la información del grande. Disminuir la dimensionalidad o varibles de los `datasets`genera un detrimento de `accuracy`, pero un `dataset`de menor tamaño es más fácil de explorar y vizualizar\n",
    "\n",
    "### Componentes principales\n",
    "\n",
    "Los componentes principales son nuevas variables que se construyen como combinaciones lineales o mezclas de las variables iniciales. Estas combinaciones se realizan de tal forma que los nuevos componentes no están correlacionados entre sí y la mayor parte de la información de las variables originales se concentra en los primeros componentes. En esencia, los datos de 10 dimensiones darían como resultado 10 componentes principales, sin embargo, el Análisis de Componentes Principales busca maximizar la información en el primer componente, seguido por el segundo y así sucesivamente, hasta representar lo que se muestra en el diagrama de dispersión.\n",
    "\n",
    "![PCA_01.png](PCA_01.png)\n",
    "\n",
    "Organizar la información en componentes principales de esta manera permite reducir la dimensionalidad sin perder mucha información, descartando aquellos componentes con poca información y considerando los restantes como las nuevas variables. Es importante destacar que los componentes principales son menos interpretables y carecen de un significado real, ya que se construyen como combinaciones lineales de las variables originales.\n",
    "\n",
    "Geométricamente, los componentes principales representan las direcciones de los datos que explican la mayor cantidad de varianza, es decir, las líneas que capturan la mayor parte de la información. En este contexto, la relación entre la varianza y la información es que a mayor varianza transportada por una línea, mayor será la dispersión de los puntos de datos a lo largo de ella\n",
    "\n",
    "![PCA_02.png](PCA_02.png)\n",
    "\n",
    "### Explicado paso a paso\n",
    "\n",
    "1. Estandarización\n",
    "\n",
    "En la etapa de normalización, se busca estandarizar el rango de las variables continuas iniciales para que todas contribuyan por igual al análisis. Esto es importante para el Análisis de Componentes Principales, ya que este método es sensible a las varianzas de las variables iniciales. Si existen diferencias significativas en los rangos de las variables, aquellas con rangos mayores dominarán sobre las de rangos más pequeños, lo que puede sesgar los resultados. Por lo tanto, es necesario transformar los datos a escalas comparables para evitar este problema. \n",
    "\n",
    "![PCA_03.png](PCA_03.png)\n",
    "\n",
    "Esto se logra restando la media y dividiendo por la desviación estándar de cada variable. Al realizar la normalización, todas las variables quedarán en la misma escala.\n",
    "\n",
    "2. Matriz de covarianza\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
